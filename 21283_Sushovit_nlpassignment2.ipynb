{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading relevant Libraries"
      ],
      "metadata": {
        "id": "QcoelGcx1iqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import requests\n",
        "import io\n",
        "# NLTK setup\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Check if GPU is available\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMuuVIKA1iKO",
        "outputId": "b8816283-5a89-47b8-b375-df476cfc0539"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading The datasets"
      ],
      "metadata": {
        "id": "l5xid6kX2Gg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download datasets using wget\n",
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/train_split.csv\n",
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/test_split.csv\n",
        "\n",
        "# Load datasets from the downloaded files\n",
        "train_data = pd.read_csv('train_split.csv')\n",
        "test_data = pd.read_csv('test_split.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL61AjO42LgJ",
        "outputId": "50ff9f18-9f17-4c67-be1c-3911fa732a53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-16 15:24:11--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/train_split.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 144474 (141K) [text/plain]\n",
            "Saving to: ‘train_split.csv’\n",
            "\n",
            "\rtrain_split.csv       0%[                    ]       0  --.-KB/s               \rtrain_split.csv     100%[===================>] 141.09K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-10-16 15:24:12 (6.29 MB/s) - ‘train_split.csv’ saved [144474/144474]\n",
            "\n",
            "--2024-10-16 15:24:12--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/test_split.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35259 (34K) [text/plain]\n",
            "Saving to: ‘test_split.csv’\n",
            "\n",
            "test_split.csv      100%[===================>]  34.43K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-10-16 15:24:12 (3.00 MB/s) - ‘test_split.csv’ saved [35259/35259]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets' Information"
      ],
      "metadata": {
        "id": "ovkY2Vog2h1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic EDA: Check for missing values\n",
        "print(\"Missing values in training set:\\n\", train_data.isnull().sum())\n",
        "print(\"Missing values in test set:\\n\", test_data.isnull().sum())\n",
        "\n",
        "# Emotions column names\n",
        "emotions = ['Joy', 'Fear', 'Anger', 'Sadness', 'Surprise']\n",
        "\n",
        "# Print value counts for each emotion in the training set\n",
        "print(\"\\nValue Counts in Training Set:\")\n",
        "for emotion in emotions:\n",
        "    print(f\"{emotion}:\\n\", train_data[emotion].value_counts())\n",
        "\n",
        "# Plot distribution of emotions in the train set\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=emotions, y=train_data[emotions].sum().values)\n",
        "plt.title('Distribution of Emotions in Train Data')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ls6vncyn2fzu",
        "outputId": "688a2bd4-5522-4316-c4e9-cb4758ff4e59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in training set:\n",
            " text        0\n",
            "Joy         0\n",
            "Fear        0\n",
            "Anger       0\n",
            "Sadness     0\n",
            "Surprise    0\n",
            "dtype: int64\n",
            "Missing values in test set:\n",
            " text        0\n",
            "Joy         0\n",
            "Fear        0\n",
            "Anger       0\n",
            "Sadness     0\n",
            "Surprise    0\n",
            "dtype: int64\n",
            "\n",
            "Value Counts in Training Set:\n",
            "Joy:\n",
            " Joy\n",
            "0    1222\n",
            "1     378\n",
            "Name: count, dtype: int64\n",
            "Fear:\n",
            " Fear\n",
            "1    931\n",
            "0    669\n",
            "Name: count, dtype: int64\n",
            "Anger:\n",
            " Anger\n",
            "0    1405\n",
            "1     195\n",
            "Name: count, dtype: int64\n",
            "Sadness:\n",
            " Sadness\n",
            "0    1097\n",
            "1     503\n",
            "Name: count, dtype: int64\n",
            "Surprise:\n",
            " Surprise\n",
            "0    1107\n",
            "1     493\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constaints"
      ],
      "metadata": {
        "id": "7tYfk3ml3I9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 100\n",
        "WINDOW_SIZE = 2\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 50\n",
        "NEG_SAMPLES = 5\n",
        "BATCH_SIZE = 512\n",
        "HIDDEN_UNITS = 64\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "EMBEDDINGS_FILE = 'custom_word2vec_embeddings.npy'\n",
        "WORD2IDX_FILE = 'word2idx_mapping.txt'\n"
      ],
      "metadata": {
        "id": "hk8GELb23G0d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec Embedding"
      ],
      "metadata": {
        "id": "33QEo_6ws-oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STOP_WORDS = set(stopwords.words('english'))\n",
        "LEMMATIZER = WordNetLemmatizer()\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    words = re.sub(r'\\W+', ' ', text.lower()).split()\n",
        "    return [LEMMATIZER.lemmatize(w) for w in words if w not in STOP_WORDS]\n",
        "\n",
        "# Apply cleaning to train data\n",
        "train_data['clean_text'] = train_data['text'].apply(clean_text)\n",
        "\n",
        "# Build vocabulary\n",
        "def build_vocabulary(sentences):\n",
        "    vocab = {word: i for i, (word, _) in enumerate(Counter(chain(*sentences)).items(), 1)}\n",
        "    return vocab, {v: k for k, v in vocab.items()}\n",
        "\n",
        "vocab, inv_vocab = build_vocabulary(train_data['clean_text'].tolist())\n",
        "VOCAB_SIZE = len(vocab)\n",
        "\n",
        "# Generate skip-gram pairs\n",
        "def generate_skipgram_pairs(sentences, vocab):\n",
        "    pairs = []\n",
        "    for sentence in sentences:\n",
        "        sentence = [vocab[word] for word in sentence if word in vocab]\n",
        "        for i, target in enumerate(sentence):\n",
        "            context_window = sentence[max(0, i - WINDOW_SIZE):i] + sentence[i + 1:i + WINDOW_SIZE + 1]\n",
        "            pairs.extend((target, context) for context in context_window)\n",
        "    return pairs\n",
        "\n",
        "# Prepare positive pairs\n",
        "positive_pairs = generate_skipgram_pairs(train_data['clean_text'], vocab)\n",
        "\n",
        "def get_negative_samples(context_word, neg_samples):\n",
        "    return random.sample([i for i in range(1, VOCAB_SIZE + 1) if i != context_word], neg_samples)\n",
        "\n",
        "# Create training data\n",
        "training_data = [(target, context, 1) for target, context in positive_pairs]\n",
        "for target, context in positive_pairs:\n",
        "    negative_contexts = get_negative_samples(context, NEG_SAMPLES)\n",
        "    training_data.extend((target, neg, 0) for neg in negative_contexts)\n",
        "\n",
        "# PyTorch Model\n",
        "class Word2Vec(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size):\n",
        "        super(Word2Vec, self).__init__()\n",
        "        self.in_embeddings = nn.Embedding(vocab_size + 1, embedding_size)\n",
        "        self.out_embeddings = nn.Embedding(vocab_size + 1, embedding_size)\n",
        "\n",
        "    def forward(self, target_words, context_words):\n",
        "        target_vectors = self.in_embeddings(target_words)\n",
        "        context_vectors = self.out_embeddings(context_words)\n",
        "        return torch.sum(target_vectors * context_vectors, dim=1)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = Word2Vec(VOCAB_SIZE, EMBEDDING_SIZE).to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Convert training data into batches\n",
        "def get_batches(data, batch_size):\n",
        "    random.shuffle(data)\n",
        "    for i in range(0, len(data), batch_size):\n",
        "        yield data[i:i + batch_size]\n",
        "\n",
        "# Prepare batch data as tensors\n",
        "def prepare_batch(batch):\n",
        "    target_words, context_words, labels = zip(*batch)\n",
        "    return (\n",
        "        torch.LongTensor(target_words).to(DEVICE),\n",
        "        torch.LongTensor(context_words).to(DEVICE),\n",
        "        torch.FloatTensor(labels).to(DEVICE)\n",
        "    )\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for batch in get_batches(training_data, BATCH_SIZE):\n",
        "        target_words, context_words, labels = prepare_batch(batch)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(target_words, context_words)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        predictions = torch.sigmoid(outputs) > 0.5\n",
        "        correct_predictions += (predictions == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {total_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Save embeddings\n",
        "np.save('custom_word2vec_embeddings.npy', model.in_embeddings.weight.detach().cpu().numpy())\n",
        "\n",
        "# Save word-to-index mapping\n",
        "with open('word2idx_mapping.txt', 'w') as f:\n",
        "    for word, idx in vocab.items():\n",
        "        f.write(f\"{word} {idx}\\n\")\n",
        "\n",
        "print(\"Training complete. Embeddings saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B_JoxT4zzn6s",
        "outputId": "a5675afc-e481-4874-89a7-74a5a0e6022c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 27466.1272, Accuracy: 50.09%\n",
            "Epoch 2/50, Loss: 18692.5159, Accuracy: 58.31%\n",
            "Epoch 3/50, Loss: 12261.7570, Accuracy: 67.14%\n",
            "Epoch 4/50, Loss: 7740.3255, Accuracy: 75.73%\n",
            "Epoch 5/50, Loss: 4662.2461, Accuracy: 83.49%\n",
            "Epoch 6/50, Loss: 2686.9571, Accuracy: 89.61%\n",
            "Epoch 7/50, Loss: 1528.6806, Accuracy: 93.70%\n",
            "Epoch 8/50, Loss: 907.6911, Accuracy: 96.07%\n",
            "Epoch 9/50, Loss: 592.0848, Accuracy: 97.31%\n",
            "Epoch 10/50, Loss: 430.2954, Accuracy: 97.95%\n",
            "Epoch 11/50, Loss: 348.1115, Accuracy: 98.24%\n",
            "Epoch 12/50, Loss: 302.1407, Accuracy: 98.44%\n",
            "Epoch 13/50, Loss: 275.4337, Accuracy: 98.52%\n",
            "Epoch 14/50, Loss: 261.7712, Accuracy: 98.54%\n",
            "Epoch 15/50, Loss: 252.5888, Accuracy: 98.57%\n",
            "Epoch 16/50, Loss: 248.5837, Accuracy: 98.58%\n",
            "Epoch 17/50, Loss: 244.6955, Accuracy: 98.59%\n",
            "Epoch 18/50, Loss: 241.0648, Accuracy: 98.59%\n",
            "Epoch 19/50, Loss: 241.0937, Accuracy: 98.58%\n",
            "Epoch 20/50, Loss: 238.0985, Accuracy: 98.58%\n",
            "Epoch 21/50, Loss: 238.8348, Accuracy: 98.58%\n",
            "Epoch 22/50, Loss: 236.8430, Accuracy: 98.57%\n",
            "Epoch 23/50, Loss: 237.4543, Accuracy: 98.60%\n",
            "Epoch 24/50, Loss: 236.4311, Accuracy: 98.59%\n",
            "Epoch 25/50, Loss: 234.7520, Accuracy: 98.58%\n",
            "Epoch 26/50, Loss: 234.7442, Accuracy: 98.59%\n",
            "Epoch 27/50, Loss: 234.3393, Accuracy: 98.61%\n",
            "Epoch 28/50, Loss: 234.1164, Accuracy: 98.58%\n",
            "Epoch 29/50, Loss: 233.6975, Accuracy: 98.60%\n",
            "Epoch 30/50, Loss: 234.6616, Accuracy: 98.59%\n",
            "Epoch 31/50, Loss: 233.4655, Accuracy: 98.58%\n",
            "Epoch 32/50, Loss: 233.3031, Accuracy: 98.59%\n",
            "Epoch 33/50, Loss: 232.7286, Accuracy: 98.58%\n",
            "Epoch 34/50, Loss: 232.7389, Accuracy: 98.61%\n",
            "Epoch 35/50, Loss: 232.9752, Accuracy: 98.59%\n",
            "Epoch 36/50, Loss: 233.6509, Accuracy: 98.60%\n",
            "Epoch 37/50, Loss: 230.3713, Accuracy: 98.61%\n",
            "Epoch 38/50, Loss: 232.4462, Accuracy: 98.59%\n",
            "Epoch 39/50, Loss: 232.0565, Accuracy: 98.61%\n",
            "Epoch 40/50, Loss: 231.3285, Accuracy: 98.60%\n",
            "Epoch 41/50, Loss: 232.2972, Accuracy: 98.60%\n",
            "Epoch 42/50, Loss: 230.7238, Accuracy: 98.60%\n",
            "Epoch 43/50, Loss: 230.8550, Accuracy: 98.59%\n",
            "Epoch 44/50, Loss: 230.0424, Accuracy: 98.59%\n",
            "Epoch 45/50, Loss: 231.5178, Accuracy: 98.62%\n",
            "Epoch 46/50, Loss: 230.0281, Accuracy: 98.60%\n",
            "Epoch 47/50, Loss: 230.2409, Accuracy: 98.58%\n",
            "Epoch 48/50, Loss: 229.4974, Accuracy: 98.60%\n",
            "Epoch 49/50, Loss: 230.7831, Accuracy: 98.59%\n",
            "Epoch 50/50, Loss: 229.2234, Accuracy: 98.61%\n",
            "Training complete. Embeddings saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train final"
      ],
      "metadata": {
        "id": "gL3QS6M7vNWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# URLs for the embeddings and word2idx mapping\n",
        "EMBEDDINGS_URL = \"https://github.com/SushovitNanda/nlp_assignment/raw/main/custom_word2vec_embeddings.npy\"\n",
        "WORD2IDX_URL = \"https://github.com/SushovitNanda/nlp_assignment/raw/main/word2idx_mapping.txt\"\n",
        "\n",
        "# Load embeddings directly from URL\n",
        "response = requests.get(EMBEDDINGS_URL)\n",
        "embeddings = np.load(io.BytesIO(response.content))  # Load from in-memory byte stream\n",
        "\n",
        "# Load word2idx mapping from URL\n",
        "response = requests.get(WORD2IDX_URL)\n",
        "word2idx = {line.split()[0]: int(line.split()[1]) for line in response.text.splitlines()}\n",
        "\n",
        "# Load train dataset\n",
        "sentences = train_data.iloc[:, 0].tolist()  # First column is sentences\n",
        "\n",
        "# Ensure labels are numeric by using pd.to_numeric and converting to torch.Tensor\n",
        "labels = train_data.iloc[:, 1:].apply(pd.to_numeric, errors='coerce').fillna(0).values  # Convert to numeric, fill NaNs\n",
        "labels = torch.Tensor(labels).to(device)\n",
        "\n",
        "# Convert sentences to embeddings by averaging word embeddings\n",
        "def sentence_to_embedding(sentence, word2idx, embeddings):\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "    word_indices = [word2idx[word] for word in tokens if word in word2idx]\n",
        "    return np.mean(embeddings[word_indices], axis=0) if word_indices else np.zeros(embeddings.shape[1])\n",
        "\n",
        "# Convert all sentences to sentence embeddings\n",
        "sentence_embeddings = torch.Tensor([sentence_to_embedding(sentence, word2idx, embeddings) for sentence in sentences]).to(device)\n",
        "\n",
        "# Define FFNN model for multi-label classification\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_units, output_size):\n",
        "        super(FFNN, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_units, hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_units, hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_units, output_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = embeddings.shape[1]  # Embedding size (e.g., 100)\n",
        "output_size = labels.shape[1]     # Number of classes (5 emotions)\n",
        "\n",
        "# Initialize the FFNN model\n",
        "model = FFNN(input_size, HIDDEN_UNITS, output_size).to(device)\n",
        "criterion = nn.BCELoss()  # Binary cross-entropy for multi-label classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, sentence_embeddings, labels, num_epochs, batch_size):\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss, correct_predictions, total_samples = 0, 0, 0\n",
        "        model.train()  # Set model to training mode\n",
        "        permutation = torch.randperm(sentence_embeddings.size(0))\n",
        "\n",
        "        for i in range(0, sentence_embeddings.size(0), batch_size):\n",
        "            indices = permutation[i:i + batch_size]\n",
        "            batch_inputs, batch_labels = sentence_embeddings[indices], labels[indices]\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_inputs)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Accuracy calculation\n",
        "            predictions = (outputs > 0.5).float()\n",
        "            correct_predictions += (predictions == batch_labels).sum().item()\n",
        "            total_samples += batch_labels.numel()\n",
        "\n",
        "        accuracy = correct_predictions / total_samples\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Train the model\n",
        "train_model(model, sentence_embeddings, labels, NUM_EPOCHS, BATCH_SIZE)\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'ffnn_multilabel_model.pth')\n"
      ],
      "metadata": {
        "id": "piJ0TpM30Zqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "40c106ea-6714-4c56-fe4f-bb8b1232bcb4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-26f68b7d5a91>:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  sentence_embeddings = torch.Tensor([sentence_to_embedding(sentence, word2idx, embeddings) for sentence in sentences]).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 27.9572, Accuracy: 0.7483\n",
            "Epoch 2/50, Loss: 23.7514, Accuracy: 0.7669\n",
            "Epoch 3/50, Loss: 23.4396, Accuracy: 0.7666\n",
            "Epoch 4/50, Loss: 23.1932, Accuracy: 0.7675\n",
            "Epoch 5/50, Loss: 22.8387, Accuracy: 0.7723\n",
            "Epoch 6/50, Loss: 22.3711, Accuracy: 0.7773\n",
            "Epoch 7/50, Loss: 21.9483, Accuracy: 0.7833\n",
            "Epoch 8/50, Loss: 21.4150, Accuracy: 0.7891\n",
            "Epoch 9/50, Loss: 20.9605, Accuracy: 0.7993\n",
            "Epoch 10/50, Loss: 20.3727, Accuracy: 0.8021\n",
            "Epoch 11/50, Loss: 19.8383, Accuracy: 0.8092\n",
            "Epoch 12/50, Loss: 19.1754, Accuracy: 0.8178\n",
            "Epoch 13/50, Loss: 18.4996, Accuracy: 0.8246\n",
            "Epoch 14/50, Loss: 17.7061, Accuracy: 0.8353\n",
            "Epoch 15/50, Loss: 17.0124, Accuracy: 0.8428\n",
            "Epoch 16/50, Loss: 16.1997, Accuracy: 0.8497\n",
            "Epoch 17/50, Loss: 15.3411, Accuracy: 0.8624\n",
            "Epoch 18/50, Loss: 14.6718, Accuracy: 0.8703\n",
            "Epoch 19/50, Loss: 14.0018, Accuracy: 0.8789\n",
            "Epoch 20/50, Loss: 13.2339, Accuracy: 0.8841\n",
            "Epoch 21/50, Loss: 12.4776, Accuracy: 0.8940\n",
            "Epoch 22/50, Loss: 12.0101, Accuracy: 0.8990\n",
            "Epoch 23/50, Loss: 11.6053, Accuracy: 0.9019\n",
            "Epoch 24/50, Loss: 10.8769, Accuracy: 0.9109\n",
            "Epoch 25/50, Loss: 10.2963, Accuracy: 0.9170\n",
            "Epoch 26/50, Loss: 9.6598, Accuracy: 0.9246\n",
            "Epoch 27/50, Loss: 9.2500, Accuracy: 0.9258\n",
            "Epoch 28/50, Loss: 8.6754, Accuracy: 0.9327\n",
            "Epoch 29/50, Loss: 8.2728, Accuracy: 0.9346\n",
            "Epoch 30/50, Loss: 7.8139, Accuracy: 0.9411\n",
            "Epoch 31/50, Loss: 7.4841, Accuracy: 0.9422\n",
            "Epoch 32/50, Loss: 7.0316, Accuracy: 0.9487\n",
            "Epoch 33/50, Loss: 7.0639, Accuracy: 0.9466\n",
            "Epoch 34/50, Loss: 6.5492, Accuracy: 0.9527\n",
            "Epoch 35/50, Loss: 6.1609, Accuracy: 0.9556\n",
            "Epoch 36/50, Loss: 5.7409, Accuracy: 0.9594\n",
            "Epoch 37/50, Loss: 5.3315, Accuracy: 0.9644\n",
            "Epoch 38/50, Loss: 4.9619, Accuracy: 0.9658\n",
            "Epoch 39/50, Loss: 4.7176, Accuracy: 0.9686\n",
            "Epoch 40/50, Loss: 4.5611, Accuracy: 0.9700\n",
            "Epoch 41/50, Loss: 4.5859, Accuracy: 0.9690\n",
            "Epoch 42/50, Loss: 4.3377, Accuracy: 0.9712\n",
            "Epoch 43/50, Loss: 4.2589, Accuracy: 0.9705\n",
            "Epoch 44/50, Loss: 3.8156, Accuracy: 0.9744\n",
            "Epoch 45/50, Loss: 3.5268, Accuracy: 0.9782\n",
            "Epoch 46/50, Loss: 3.3353, Accuracy: 0.9799\n",
            "Epoch 47/50, Loss: 3.2098, Accuracy: 0.9801\n",
            "Epoch 48/50, Loss: 3.3135, Accuracy: 0.9792\n",
            "Epoch 49/50, Loss: 3.1719, Accuracy: 0.9815\n",
            "Epoch 50/50, Loss: 3.0519, Accuracy: 0.9804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exBrr5ShW3Hw"
      },
      "source": [
        "# inference final"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URLs for the embeddings, word2idx mapping, and trained model\n",
        "EMBEDDINGS_URL = \"https://github.com/SushovitNanda/nlp_assignment/raw/main/custom_word2vec_embeddings.npy\"\n",
        "WORD2IDX_URL = \"https://github.com/SushovitNanda/nlp_assignment/raw/main/word2idx_mapping.txt\"\n",
        "MODEL_URL = \"https://github.com/SushovitNanda/nlp_assignment/raw/main/ffnn_multilabel_model.pth\"\n",
        "\n",
        "# Load embeddings directly from URL\n",
        "response = requests.get(EMBEDDINGS_URL)\n",
        "embeddings = np.load(io.BytesIO(response.content))  # Load from in-memory byte stream\n",
        "\n",
        "# Load word2idx mapping from URL\n",
        "response = requests.get(WORD2IDX_URL)\n",
        "word2idx = {line.split()[0]: int(line.split()[1]) for line in response.text.splitlines()}\n",
        "\n",
        "# Load pre-trained model from URL\n",
        "response = requests.get(MODEL_URL)\n",
        "model_data = io.BytesIO(response.content)  # Use in-memory byte stream for the model\n",
        "\n",
        "def sentence_to_embedding(sentence, word2idx, embeddings):\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "    word_indices = [word2idx[word] for word in tokens if word in word2idx]\n",
        "    return np.mean(embeddings[word_indices], axis=0) if word_indices else np.zeros(embeddings.shape[1])\n",
        "\n",
        "# Convert all test sentences to embeddings\n",
        "test_sentence_embeddings = np.array([sentence_to_embedding(sentence, word2idx, embeddings) for sentence in test_data['text']])\n",
        "test_labels = test_data[['Joy', 'Fear', 'Anger', 'Sadness', 'Surprise']].values\n",
        "\n",
        "# Convert test data to tensors\n",
        "test_sentence_embeddings = torch.Tensor(test_sentence_embeddings).to(device)\n",
        "test_labels = torch.Tensor(test_labels).to(device)\n",
        "\n",
        "# Define FFNN model (match output size to the saved model's 6 outputs)\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_units, output_size=6):  # Set output_size to 6\n",
        "        super(FFNN, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_units, hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_units, hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_units, output_size),  # 6 output units to match checkpoint\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Model parameters\n",
        "input_size = embeddings.shape[1]  # Embedding size (e.g., 100)\n",
        "output_size = 6  # Model expects 6 output classes\n",
        "\n",
        "# Load the trained model\n",
        "model = FFNN(input_size, HIDDEN_UNITS, output_size)\n",
        "model.load_state_dict(torch.load(model_data, map_location=device))  # Load model directly from memory\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Prepare DataLoader\n",
        "test_dataset = TensorDataset(test_sentence_embeddings, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            all_targets.append(labels.cpu().numpy())\n",
        "            all_predictions.append(outputs.detach().cpu().numpy())\n",
        "\n",
        "    # Concatenate all predictions and targets\n",
        "    all_targets = np.vstack(all_targets)\n",
        "    all_predictions = np.vstack(all_predictions)\n",
        "\n",
        "    # Slice off the extra class from predictions (we assume the last class is the extra one)\n",
        "    all_predictions = all_predictions[:, :5]\n",
        "\n",
        "    # Threshold the predictions at 0.5\n",
        "    predictions_binary = (all_predictions > 0.5).astype(int)\n",
        "\n",
        "    # Compute Macro F1-score and classification report\n",
        "    f1_macro = f1_score(all_targets, predictions_binary, average='macro', zero_division=0)\n",
        "    class_names = ['Joy', 'Fear', 'Anger', 'Sadness', 'Surprise']\n",
        "    classification_rep = classification_report(all_targets, predictions_binary, target_names=class_names, zero_division=0)\n",
        "\n",
        "    print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_rep)\n",
        "\n",
        "# Main function to run the evaluation\n",
        "def main():\n",
        "    evaluate_model(model, test_loader, device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "WYh-qsAhxtCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f32dbc-8317-4492-dca8-57d4a67f1d36"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro F1-Score: 0.3579\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Joy       0.25      0.18      0.21        94\n",
            "        Fear       0.61      0.65      0.63       232\n",
            "       Anger       0.23      0.17      0.20        52\n",
            "     Sadness       0.35      0.33      0.34       126\n",
            "    Surprise       0.40      0.42      0.41       124\n",
            "\n",
            "   micro avg       0.45      0.43      0.44       628\n",
            "   macro avg       0.37      0.35      0.36       628\n",
            "weighted avg       0.43      0.43      0.43       628\n",
            " samples avg       0.38      0.38      0.35       628\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-7b6d95de0f63>:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_data, map_location=device))  # Load model directly from memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MdKf_pLOH7Kn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QcoelGcx1iqj",
        "l5xid6kX2Gg_",
        "ovkY2Vog2h1x",
        "7tYfk3ml3I9k",
        "33QEo_6ws-oa"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}