{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b95718b6b6b543f388243701e77bec85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a492662260e047e894806e1e6dd5ea61",
              "IPY_MODEL_f6edfcb733ec47988cb57a3e11f9816a",
              "IPY_MODEL_531d8e13258f4719af66317ce6110a2e"
            ],
            "layout": "IPY_MODEL_71e94a34ac6347a097cf6879d02362fc"
          }
        },
        "a492662260e047e894806e1e6dd5ea61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e4b2dd3c5014765b89c18dc241cc539",
            "placeholder": "​",
            "style": "IPY_MODEL_a24203d8e3244cb5a0c4cbdc3a0f9eaf",
            "value": "Map: 100%"
          }
        },
        "f6edfcb733ec47988cb57a3e11f9816a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d7c148d0087403e9c5882e4c5410fad",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85554508a8df49b1b2b707cfb52dc4db",
            "value": 400
          }
        },
        "531d8e13258f4719af66317ce6110a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04cf3d8ab68f486f94d6e1b646337633",
            "placeholder": "​",
            "style": "IPY_MODEL_e9118ba9e3d6403bb5336f0704be5859",
            "value": " 400/400 [00:00&lt;00:00, 1579.42 examples/s]"
          }
        },
        "71e94a34ac6347a097cf6879d02362fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4b2dd3c5014765b89c18dc241cc539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24203d8e3244cb5a0c4cbdc3a0f9eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d7c148d0087403e9c5882e4c5410fad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85554508a8df49b1b2b707cfb52dc4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04cf3d8ab68f486f94d6e1b646337633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9118ba9e3d6403bb5336f0704be5859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MSdrhW15sUUn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers torch sklearn\n",
        "!pip install evaluate\n",
        "!pip install accelerate scikit-learn safetensors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import gdown\n",
        "from transformers import (\n",
        "    RobertaTokenizer,\n",
        "    RobertaForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from safetensors.torch import load_file\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "import evaluate\n",
        "from datasets import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import shutil\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "rpeNfj_mKO4x"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/train_split.csv\n",
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/test_split.csv"
      ],
      "metadata": {
        "id": "BYoFGw0KwhOQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training of Roberta Model"
      ],
      "metadata": {
        "id": "StcbElaEYjjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load data\n",
        "# train_df = pd.read_csv(\"train_split.csv\")\n",
        "\n",
        "# # Convert label columns to float (important for BCEWithLogitsLoss)\n",
        "# label_columns = ['Joy', 'Fear', 'Anger', 'Sadness', 'Surprise']\n",
        "# train_df[label_columns] = train_df[label_columns].astype(float)\n",
        "\n",
        "# # Split train_df into train and validation sets\n",
        "# train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Convert train and validation sets to Hugging Face Dataset format\n",
        "# train_dataset = datasets.Dataset.from_pandas(train_data)\n",
        "# val_dataset = datasets.Dataset.from_pandas(val_data)\n",
        "\n",
        "# # Load the tokenizer\n",
        "# tokenizer = RobertaTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
        "\n",
        "# # Define a tokenization function\n",
        "# def tokenize_function(example):\n",
        "#     return tokenizer(example['text'], truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# # Tokenize datasets\n",
        "# train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "# val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# # Define labels as multi-hot encoding\n",
        "# def encode_labels(example):\n",
        "#     example['labels'] = [example['Joy'], example['Fear'], example['Anger'], example['Sadness'], example['Surprise']]\n",
        "#     return example\n",
        "\n",
        "# # Apply label encoding\n",
        "# train_dataset = train_dataset.map(encode_labels)\n",
        "# val_dataset = val_dataset.map(encode_labels)\n",
        "\n",
        "# # Set up a data collator\n",
        "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# # Load Roberta model with multi-label classification configuration\n",
        "# model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-base\", num_labels=5, problem_type=\"multi_label_classification\")\n",
        "\n",
        "# # Load F1 metric with macro averaging\n",
        "# f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "# # Define custom metric computation function\n",
        "# def compute_metrics(eval_pred):\n",
        "#     logits, labels = eval_pred\n",
        "#     predictions = (logits > 0).astype(int)\n",
        "#     predictions = predictions.reshape(-1)\n",
        "#     labels = labels.astype(int).reshape(-1)\n",
        "#     f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
        "#     return {\"f1\": f1[\"f1\"]}\n",
        "\n",
        "# # TrainingArguments with early stopping callback\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"./results\",\n",
        "#     evaluation_strategy=\"epoch\",\n",
        "#     save_strategy=\"epoch\",\n",
        "#     learning_rate=1e-5,\n",
        "#     per_device_train_batch_size=8,\n",
        "#     per_device_eval_batch_size=8,\n",
        "#     num_train_epochs=10,\n",
        "#     weight_decay=0.01,\n",
        "#     logging_dir=\"./logs\",\n",
        "#     logging_steps=10,\n",
        "#     load_best_model_at_end=True,\n",
        "#     metric_for_best_model=\"f1\",\n",
        "#     save_total_limit=1,\n",
        "#     greater_is_better=True,\n",
        "#     report_to=\"none\",\n",
        "# )\n",
        "\n",
        "# # Initialize Trainer with EarlyStoppingCallback\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=val_dataset,\n",
        "#     tokenizer=tokenizer,\n",
        "#     data_collator=data_collator,\n",
        "#     compute_metrics=compute_metrics,\n",
        "#     callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "# )\n"
      ],
      "metadata": {
        "id": "8r_6CSYavECG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "#trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "NwNm0HT4wX4U",
        "outputId": "edfc2105-bb07-4a1a-a87a-09ea8344102d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1280' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1280/1600 05:01 < 01:15, 4.24 it/s, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.474100</td>\n",
              "      <td>0.449991</td>\n",
              "      <td>0.743610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.402900</td>\n",
              "      <td>0.400036</td>\n",
              "      <td>0.793844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.400300</td>\n",
              "      <td>0.364258</td>\n",
              "      <td>0.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.266100</td>\n",
              "      <td>0.367885</td>\n",
              "      <td>0.811051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.224800</td>\n",
              "      <td>0.363891</td>\n",
              "      <td>0.820330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.208900</td>\n",
              "      <td>0.365356</td>\n",
              "      <td>0.823419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.189000</td>\n",
              "      <td>0.365047</td>\n",
              "      <td>0.818436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.171700</td>\n",
              "      <td>0.360568</td>\n",
              "      <td>0.822253</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1280, training_loss=0.3049406227655709, metrics={'train_runtime': 303.0949, 'train_samples_per_second': 42.231, 'train_steps_per_second': 5.279, 'total_flos': 505186833530880.0, 'train_loss': 0.3049406227655709, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Upload model weights to GitHub**"
      ],
      "metadata": {
        "id": "zX1WTjgpYx_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model and tokenizer\n",
        "#model.save_pretrained(\"./saved_model\")\n",
        "#tokenizer.save_pretrained(\"./saved_model\")\n",
        "\n",
        "# Zip the saved_model directory\n",
        "#shutil.make_archive(\"saved_model\", 'zip', \"./saved_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "48saima7x229",
        "outputId": "3bdae08e-a803-482d-ede8-d9b36ecb92e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/saved_model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference of Test Dataset"
      ],
      "metadata": {
        "id": "OIBAODLrY7w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to save model files\n",
        "model_path = './Roberta_Weights'\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "# List of URLs to download\n",
        "model_files = {\n",
        "    \"config.json\": \"https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/config.json\",\n",
        "    \"merges.txt\": \"https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/merges.txt\",\n",
        "    \"model.safetensors\": \"https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/model.safetensors\",\n",
        "    \"special_tokens_map.json\": \"https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/special_tokens_map.json\",\n",
        "    \"tokenizer_config.json\": \"https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/tokenizer_config.json\",\n",
        "    \"vocab.json\": \"https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/vocab.json\"\n",
        "}\n",
        "\n",
        "# Download each file using wget\n",
        "for filename, url in model_files.items():\n",
        "    !wget -P {model_path} {url}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q1rVeycFV-wD",
        "outputId": "db1f5e02-5ad8-4019-96d3-8921bd81f920"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-12 17:07:22--  https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/config.json\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SushovitNanda/nlp_assignment/main/Roberta_Weights/config.json [following]\n",
            "--2024-11-12 17:07:22--  https://raw.githubusercontent.com/SushovitNanda/nlp_assignment/main/Roberta_Weights/config.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 975 [text/plain]\n",
            "Saving to: ‘./Roberta_Weights/config.json’\n",
            "\n",
            "config.json         100%[===================>]     975  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-12 17:07:22 (45.0 MB/s) - ‘./Roberta_Weights/config.json’ saved [975/975]\n",
            "\n",
            "--2024-11-12 17:07:22--  https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/merges.txt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SushovitNanda/nlp_assignment/main/Roberta_Weights/merges.txt [following]\n",
            "--2024-11-12 17:07:23--  https://raw.githubusercontent.com/SushovitNanda/nlp_assignment/main/Roberta_Weights/merges.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 456318 (446K) [text/plain]\n",
            "Saving to: ‘./Roberta_Weights/merges.txt’\n",
            "\n",
            "merges.txt          100%[===================>] 445.62K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-11-12 17:07:23 (14.8 MB/s) - ‘./Roberta_Weights/merges.txt’ saved [456318/456318]\n",
            "\n",
            "--2024-11-12 17:07:23--  https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/model.safetensors\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/SushovitNanda/nlp_assignment/main/Roberta_Weights/model.safetensors [following]\n",
            "--2024-11-12 17:07:23--  https://media.githubusercontent.com/media/SushovitNanda/nlp_assignment/main/Roberta_Weights/model.safetensors\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 498622052 (476M) [application/octet-stream]\n",
            "Saving to: ‘./Roberta_Weights/model.safetensors’\n",
            "\n",
            "model.safetensors   100%[===================>] 475.52M  77.9MB/s    in 7.6s    \n",
            "\n",
            "2024-11-12 17:07:43 (62.4 MB/s) - ‘./Roberta_Weights/model.safetensors’ saved [498622052/498622052]\n",
            "\n",
            "--2024-11-12 17:07:43--  https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/special_tokens_map.json\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SushovitNanda/nlp_assignment/main/Roberta_Weights/special_tokens_map.json [following]\n",
            "--2024-11-12 17:07:43--  https://raw.githubusercontent.com/SushovitNanda/nlp_assignment/main/Roberta_Weights/special_tokens_map.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 958 [text/plain]\n",
            "Saving to: ‘./Roberta_Weights/special_tokens_map.json’\n",
            "\n",
            "special_tokens_map. 100%[===================>]     958  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-12 17:07:44 (57.1 MB/s) - ‘./Roberta_Weights/special_tokens_map.json’ saved [958/958]\n",
            "\n",
            "--2024-11-12 17:07:44--  https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/tokenizer_config.json\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SushovitNanda/nlp_assignment/main/Roberta_Weights/tokenizer_config.json [following]\n",
            "--2024-11-12 17:07:44--  https://raw.githubusercontent.com/SushovitNanda/nlp_assignment/main/Roberta_Weights/tokenizer_config.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘./Roberta_Weights/tokenizer_config.json’\n",
            "\n",
            "tokenizer_config.js 100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-12 17:07:44 (80.0 MB/s) - ‘./Roberta_Weights/tokenizer_config.json’ saved [1191/1191]\n",
            "\n",
            "--2024-11-12 17:07:44--  https://github.com/SushovitNanda/nlp_assignment/raw/main/Roberta_Weights/vocab.json\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SushovitNanda/nlp_assignment/main/Roberta_Weights/vocab.json [following]\n",
            "--2024-11-12 17:07:45--  https://raw.githubusercontent.com/SushovitNanda/nlp_assignment/main/Roberta_Weights/vocab.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 999355 (976K) [text/plain]\n",
            "Saving to: ‘./Roberta_Weights/vocab.json’\n",
            "\n",
            "vocab.json          100%[===================>] 975.93K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-11-12 17:07:45 (26.2 MB/s) - ‘./Roberta_Weights/vocab.json’ saved [999355/999355]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Load the model with the .safetensors file\n",
        "state_dict = load_file(os.path.join(model_path, \"model.safetensors\"))\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    model_path,\n",
        "    state_dict=state_dict\n",
        ")\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Load test data\n",
        "test_df = pd.read_csv(\"test_split.csv\")\n",
        "label_columns = ['Joy', 'Fear', 'Anger', 'Sadness', 'Surprise']\n",
        "test_df[label_columns] = test_df[label_columns].astype(float)\n",
        "\n",
        "# Convert Pandas DataFrame to Hugging Face Dataset\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Preprocess function to tokenize the text\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "# Apply the preprocessing\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Prepare DataLoader with DataCollatorWithPadding to handle padding automatically\n",
        "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "test_dataset = test_dataset.remove_columns(['text'])\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)\n",
        "\n",
        "# Prediction function with F1 macro calculation\n",
        "def predict(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "\n",
        "            # Move tensors to GPU if available\n",
        "            if torch.cuda.is_available():\n",
        "                input_ids = input_ids.cuda()\n",
        "                attention_mask = attention_mask.cuda()\n",
        "                model.cuda()\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.sigmoid(logits).cpu().numpy()  # Apply sigmoid for multi-label classification\n",
        "            predictions.extend(preds)\n",
        "    return predictions\n",
        "\n",
        "# Run prediction on test dataset\n",
        "preds = predict(model, test_loader)\n",
        "\n",
        "# Convert predictions to DataFrame\n",
        "preds_df = pd.DataFrame(preds, columns=label_columns)\n",
        "\n",
        "# Post-process predictions to binary values (0 or 1 based on threshold 0.5)\n",
        "binary_preds_df = (preds_df >= 0.5).astype(int)\n",
        "\n",
        "# Extract true labels from the test DataFrame\n",
        "true_labels_df = test_df[label_columns]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b95718b6b6b543f388243701e77bec85",
            "a492662260e047e894806e1e6dd5ea61",
            "f6edfcb733ec47988cb57a3e11f9816a",
            "531d8e13258f4719af66317ce6110a2e",
            "71e94a34ac6347a097cf6879d02362fc",
            "5e4b2dd3c5014765b89c18dc241cc539",
            "a24203d8e3244cb5a0c4cbdc3a0f9eaf",
            "2d7c148d0087403e9c5882e4c5410fad",
            "85554508a8df49b1b2b707cfb52dc4db",
            "04cf3d8ab68f486f94d6e1b646337633",
            "e9118ba9e3d6403bb5336f0704be5859"
          ]
        },
        "id": "zCGqwVhrVm7H",
        "outputId": "1e9de325-315c-4a80-ef3e-c7b5f4b92c52"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b95718b6b6b543f388243701e77bec85"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the classification report\n",
        "report = classification_report(true_labels_df, binary_preds_df, target_names=label_columns)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# F1 macro score\n",
        "f1_macro = f1_score(true_labels_df, binary_preds_df, average='macro')\n",
        "print(\"F1 Macro Score:\", f1_macro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvP2FlqQWbUr",
        "outputId": "a60becde-3923-4c45-bbcd-c30ba26fd051"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         Joy       0.71      0.71      0.71        94\n",
            "        Fear       0.84      0.85      0.84       232\n",
            "       Anger       0.75      0.35      0.47        52\n",
            "     Sadness       0.72      0.61      0.66       126\n",
            "    Surprise       0.68      0.78      0.73       124\n",
            "\n",
            "   micro avg       0.76      0.73      0.74       628\n",
            "   macro avg       0.74      0.66      0.68       628\n",
            "weighted avg       0.76      0.73      0.73       628\n",
            " samples avg       0.69      0.68      0.66       628\n",
            "\n",
            "F1 Macro Score: 0.6836671628903819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xJiNiKtzZTuD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}